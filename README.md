# ğŸ™ï¸ Whisper Transcription Tool

Beautiful command-line application for transcribing audio files using [OpenAI Whisper Large-v3](https://huggingface.co/openai/whisper-large-v3) model.

## âœ¨ Features

- ğŸ¯ High accuracy transcription with Whisper Large-v3
- ğŸš€ GPU (CUDA) support for accelerated processing
- ğŸŒ Automatic language detection or manual language specification
- ğŸ“Š Beautiful progress indicators in Claude Code style
- ğŸ“ Preview of transcription results
- ğŸ’¾ Save transcription to text file
- ğŸ”„ Multiple model options (large, turbo, medium, small)

## ğŸµ Supported Audio Formats

- MP3
- WAV
- M4A
- FLAC
- OGG
- Other formats supported by ffmpeg

## ğŸ“‹ Requirements

- Python 3.8 or higher
- ffmpeg (for audio processing)

### Installing ffmpeg

**macOS:**
```bash
brew install ffmpeg
```

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

**Windows:**
Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH.

## ğŸš€ Installation

### 1. Clone the repository or copy the files

```bash
cd whisp
```

### 2. Create a virtual environment

```bash
python3 -m venv venv
```

### 3. Activate the virtual environment

**macOS/Linux:**
```bash
source venv/bin/activate
```

**Windows:**
```bash
venv\Scripts\activate
```

### 4. Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

> âš ï¸ **Note:** The first run will take some time as the Whisper model (~3GB for large) will be downloaded from HuggingFace.

## ğŸ’» Usage

### Basic usage

```bash
python whisp.py input.mp3 output.txt
```

### With model and language specification

```bash
python whisp.py audio.wav transcript.txt --model large --language en
```

### Model Selection

4 Whisper models are available:

| Model | Size | Accuracy | Speed | Recommendation |
|-------|------|----------|-------|----------------|
| **large** | ~3GB | Best | Slow | âœ… Default, for academic content |
| **turbo** | ~1.5GB | Same as large | 8x faster | âš¡ Recommended for most tasks |
| **medium** | ~1.5GB | Good | 2-3x faster | âš–ï¸ Balance of speed and quality |
| **small** | ~466MB | Basic | Fast | ğŸš€ For simple tasks |

### Examples

**German lecture (maximum accuracy):**
```bash
python whisp.py lecture.mp3 transcript.txt --model large --language de
```

**Fast podcast transcription:**
```bash
python whisp.py podcast.m4a transcript.txt --model turbo --language en
```

**Automatic language detection:**
```bash
python whisp.py interview.mp3 interview_text.txt --model medium
```

### Command help

```bash
python whisp.py --help
```

## ğŸ“Š Example Output

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                         â”‚
â”‚  ğŸ™ï¸  Whisper Transcription Tool        â”‚
â”‚  Powered by OpenAI Whisper Large-v3    â”‚
â”‚                                         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Device: cuda:0
GPU: NVIDIA GeForce RTX 3080

âš™ï¸  Initializing Whisper model...
Model: turbo (Same accuracy as large, 8x faster, ~1.5GB)
âœ“ Model loaded successfully on cuda:0

ğŸ”§ Creating transcription pipeline...
âœ“ Pipeline ready

ğŸµ Transcribing audio file...
Input: audio.mp3

â ‹ Processing audio... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0:00:15

ğŸ’¾ Saving transcription...
âœ“ Transcription saved to: transcript.txt

ğŸ“ Preview:
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚                                         â”‚
â”‚  Hello and welcome to today's podcast. â”‚
â”‚  In this episode, we'll be discussing...â”‚
â”‚                                         â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Stats: 523 words, 3142 characters

âœ¨ Transcription completed successfully!
```

## âš¡ Performance

- **With GPU (CUDA):** ~10-20x faster than real-time
- **With CPU:** ~2-5x slower than real-time

> ğŸ’¡ **Tip:** For long audio files, using GPU is highly recommended.

## ğŸ”§ Additional Settings

### Model Selection Recommendations

- **large** - use for academic lectures, medical recordings, technical documentation
- **turbo** - optimal choice for most tasks: podcasts, interviews, meetings
- **medium** - for fast processing of simple content on weaker machines
- **small** - only for simple recordings with good audio quality

### Supported Languages

Whisper supports 99+ languages. Most popular:
- `en` - English
- `ru` - Russian
- `es` - Spanish
- `fr` - French
- `de` - German
- `it` - Italian
- `ja` - Japanese
- `ko` - Korean
- `zh` - Chinese

Full list: [Whisper Language Support](https://github.com/openai/whisper#available-models-and-languages)

## ğŸ› Troubleshooting

### "CUDA out of memory" error

If you don't have enough GPU memory, reduce `batch_size` in the code:

```python
batch_size=8,  # instead of 16
```

### "ffmpeg not found" error

Make sure ffmpeg is installed and available in PATH:

```bash
ffmpeg -version
```

### Slow performance

- Make sure GPU is being used (output should show `cuda:0`)
- Check that PyTorch with CUDA support is installed:

```bash
python -c "import torch; print(torch.cuda.is_available())"
```

If output is `False`, reinstall PyTorch:

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“¦ Project Structure

```
whisp/
â”œâ”€â”€ whisp.py                # Main script
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Documentation
â””â”€â”€ venv/                   # Virtual environment (created during installation)
```

## ğŸ“„ License

This project uses the Whisper model from OpenAI. See [Whisper License](https://github.com/openai/whisper/blob/main/LICENSE) for details.

## ğŸ¤ Contributing

Questions and suggestions are welcome! Create issues or pull requests.

## ğŸ“š Useful Links

- [Whisper Large-v3 on HuggingFace](https://huggingface.co/openai/whisper-large-v3)
- [Whisper Large-v3-Turbo on HuggingFace](https://huggingface.co/openai/whisper-large-v3-turbo)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [OpenAI Whisper GitHub](https://github.com/openai/whisper)

---

**Made with â¤ï¸ using OpenAI Whisper and HuggingFace Transformers**
