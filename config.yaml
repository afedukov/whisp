# =============================================================================
# Whisp Configuration File
# =============================================================================
# This file contains all configurable settings for the whisp transcription tool.
# Edit these values to customize the default behavior.
# Command-line arguments will override these settings.

# =============================================================================
# Model Settings
# =============================================================================
model:
  # Default Whisper model to use for transcription
  # Options: turbo, large, large-v2, medium, small, base
  #   - turbo:    ~800MB, 8x faster than large, good accuracy, multilingual (recommended)
  #   - large:    ~3GB, best accuracy (latest v3), slower processing
  #   - large-v2: ~3GB, previous large version, slightly faster than v3
  #   - medium:   ~1.5GB, good balance of speed and accuracy
  #   - small:    ~466MB, fast but lower accuracy
  #   - base:     ~145MB, very fast, basic accuracy
  default: "turbo"

  # Compute type for CPU inference
  # Options: int8, float32
  #   - int8:    Faster, lower memory usage (recommended for CPU)
  #   - float32: Higher precision, more memory
  compute_type_cpu: "int8"

  # Compute type for GPU (CUDA) inference
  # Options: float16, float32, int8_float16
  #   - float16:      Best balance of speed and memory for GPU (recommended)
  #   - float32:      Higher precision, more VRAM usage
  #   - int8_float16: Fastest, lowest VRAM, slightly lower accuracy
  compute_type_gpu: "float16"

# =============================================================================
# Transcription Settings
# =============================================================================
transcription:
  # Default language for transcription
  # Leave empty ("") for automatic language detection
  # Examples: "de" (German), "en" (English), "ru" (Russian), "es" (Spanish)
  # Full list: https://github.com/openai/whisper#available-models-and-languages
  default_language: ""

  # Beam size for beam search decoding
  # Higher values = better accuracy but slower processing
  # Range: 1-10 (default: 5)
  #   - 1:  Fastest, greedy decoding
  #   - 5:  Good balance (recommended)
  #   - 10: Best accuracy, slowest
  beam_size: 5

  # Voice Activity Detection (VAD) - skip silence in audio
  # Speeds up transcription by ignoring silent parts
  # Set to false if you need to preserve timing information
  vad_filter: true

  # Minimum silence duration in milliseconds to be skipped by VAD
  # Lower values = more aggressive silence skipping
  # Range: 100-2000 (default: 500)
  min_silence_duration_ms: 500

# =============================================================================
# Output Settings
# =============================================================================
output:
  # Preview length in characters shown after transcription
  # Set to 0 to disable preview
  preview_length: 500

# =============================================================================
# Recording Settings (for microphone recording mode)
# =============================================================================
recording:
  # Sample rate for recording (16kHz optimal for Whisper)
  sample_rate: 16000

  # Audio channels (1=mono, 2=stereo) - mono recommended for speech
  channels: 1

  # Default recording device (pre-select microphone or show interactive menu)
  # Options:
  #   -1                      → Show interactive device selection menu
  #   "BlackHole 2ch"         → Auto-use device by exact name (recommended!)
  #   "BlackHole"             → Auto-use device by partial name match
  #   4                       → Auto-use device by index (unreliable, may change!)
  # To see available devices, run: python whisp.py record
  default_device: "BlackHole"

  # Show audio level meter during recording (requires more CPU)
  show_level_meter: true

  # Directory to save recordings (only used when keep_recording is true)
  # Empty = system temp directory (recordings will be deleted after transcription)
  # Path = save recordings with timestamp to this directory
  save_dir: "~/Records"

  # Keep recording file after transcription
  # true = save with timestamp in save_dir, false = delete after transcription
  keep_recording: true

  # Compress recording to save space ("m4a" or "wav")
  # m4a is ~10x smaller than wav with minimal quality loss
  compress_format: "m4a"

# =============================================================================
# Translation Settings (OpenAI API)
# =============================================================================
translation:
  # OpenAI API key for translation
  # Get one at: https://platform.openai.com/api-keys
  # Or set environment variable: OPENAI_API_KEY
  openai_api_key: ""

  # OpenAI model for translation
  # Recommended: gpt-4o-mini (fast, cheap, high quality)
  # Other options: gpt-5-nano, gpt-5-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
  model: "gpt-4o-mini"

  # Translation prompt (customizable)
  # Variables: {source_language}, {target_language}, {text}
  prompt: |
    Translate the following text from {source_language} to {target_language}.

    CRITICAL REQUIREMENTS:
    1. Translate EVERYTHING - do not omit, shorten, or summarize any content
    2. Maintain the exact meaning and tone of the original text
    3. Preserve all technical terms, names, and numbers exactly as they appear
    4. Do NOT add any explanations, notes, or comments of your own
    5. Organize the translated text into logical paragraphs based on topic changes and natural breaks in the content
    6. Keep paragraph structure clear and readable

    Provide ONLY the translated text, nothing else.

    Text to translate:
    {text}
