# =============================================================================
# Whisp Configuration File
# =============================================================================
# This file contains all configurable settings for the whisp transcription tool.
# Edit these values to customize the default behavior.
# Command-line arguments will override these settings.

# =============================================================================
# Model Settings
# =============================================================================
model:
  # Default Whisper model to use for transcription
  # Options: turbo, large, large-v2, medium, small, base
  #   - turbo:    ~800MB, 8x faster than large, good accuracy, multilingual (recommended)
  #   - large:    ~3GB, best accuracy (latest v3), slower processing
  #   - large-v2: ~3GB, previous large version, slightly faster than v3
  #   - medium:   ~1.5GB, good balance of speed and accuracy
  #   - small:    ~466MB, fast but lower accuracy
  #   - base:     ~145MB, very fast, basic accuracy
  default: "turbo"

  # Compute type for CPU inference
  # Options: int8, float32
  #   - int8:    Faster, lower memory usage (recommended for CPU)
  #   - float32: Higher precision, more memory
  compute_type_cpu: "int8"

  # Compute type for GPU (CUDA) inference
  # Options: float16, float32, int8_float16
  #   - float16:      Best balance of speed and memory for GPU (recommended)
  #   - float32:      Higher precision, more VRAM usage
  #   - int8_float16: Fastest, lowest VRAM, slightly lower accuracy
  compute_type_gpu: "float16"

# =============================================================================
# Transcription Settings
# =============================================================================
transcription:
  # Default language for transcription
  # Leave empty ("") for automatic language detection
  # Examples: "de" (German), "en" (English), "ru" (Russian), "es" (Spanish)
  # Full list: https://github.com/openai/whisper#available-models-and-languages
  default_language: ""

  # Beam size for beam search decoding
  # Higher values = better accuracy but slower processing
  # Range: 1-10 (default: 5)
  #   - 1:  Fastest, greedy decoding
  #   - 5:  Good balance (recommended)
  #   - 10: Best accuracy, slowest
  beam_size: 5

  # Voice Activity Detection (VAD) - skip silence in audio
  # Speeds up transcription by ignoring silent parts
  # Set to false if you need to preserve timing information
  vad_filter: true

  # Minimum silence duration in milliseconds to be skipped by VAD
  # Lower values = more aggressive silence skipping
  # Range: 100-2000 (default: 500)
  min_silence_duration_ms: 500

# =============================================================================
# Output Settings
# =============================================================================
output:
  # Preview length in characters shown after transcription
  # Set to 0 to disable preview
  preview_length: 500

# =============================================================================
# Recording Settings (for microphone recording mode)
# =============================================================================
recording:
  # Sample rate for recording (16kHz optimal for Whisper)
  sample_rate: 16000

  # Audio channels (1=mono, 2=stereo) - mono recommended for speech
  channels: 1

  # Default recording device (pre-select microphone or show interactive menu)
  # Options:
  #   -1                      → Show interactive device selection menu
  #   "BlackHole 2ch"         → Auto-use device by exact name (recommended!)
  #   "BlackHole"             → Auto-use device by partial name match
  #   4                       → Auto-use device by index (unreliable, may change!)
  # To see available devices, run: python whisp.py record
  default_device: "BlackHole"

  # Show audio level meter during recording (requires more CPU)
  show_level_meter: true

  # Directory to save recordings (only used when keep_recording is true)
  # Empty = system temp directory (recordings will be deleted after transcription)
  # Path = save recordings with timestamp to this directory
  save_dir: "~/Records"

  # Keep recording file after transcription
  # true = save with timestamp in save_dir, false = delete after transcription
  keep_recording: true

  # Compress recording to save space ("m4a" or "wav")
  # m4a is ~10x smaller than wav with minimal quality loss
  compress_format: "m4a"

# =============================================================================
# Translation Settings (OpenAI API)
# =============================================================================
translation:
  # OpenAI API key for translation
  # Get one at: https://platform.openai.com/api-keys
  # Or set environment variable: OPENAI_API_KEY
  openai_api_key: ""

  # OpenAI model for translation
  # Recommended:
  #   - gpt-5-mini (default, recommended)
  #   - gpt-5-nano
  #   - gpt-4o-mini
  model: "gpt-5-mini"

  # Temperature for sampling (creativity vs determinism)
  # Range: 0.0 to 1.0 (default: 0.3)
  # Note: Some specialized models (e.g., gpt-5-mini, gpt-5-nano) may require temperature=1.0 or specific values
  temperature: 1.0

  # System prompt: Defines the AI's persona and general behavior
  system_prompt: >
    You are a professional academic translator and editor. You specialize in cleaning up and translating
    imperfect speech transcripts while maintaining strict factual accuracy and preserving the speaker’s intent.

  # User prompt: The actual instruction and text to translate
  # Variables available: {source_language}, {target_language}, {text}
  user_prompt: |
    Task: Translate the following ASR transcript of a spoken lecture from {source_language} to {target_language}.

    Context: The source text is a raw automated transcription. It contains phonetic errors, misheard words,
    and run-on sentences.

    CRITICAL INSTRUCTIONS (Priority Order):
    1) Fidelity & Completeness:
       - Translate the full content.
       - Do NOT summarize. Do NOT omit digressions. Do NOT add external info or explanations.
       - Preserve the speaker’s claims, hedging, and level of certainty (do not strengthen or weaken statements).

    2) ASR Repair:
       - Correct only obvious transcription errors when the intended wording is clear from context.
       - If a word sounds like a phonetic error (e.g. similar sounding but wrong meaning), translate the intended meaning based on context.
       - Prefer a best-effort repair over [unclear] when a likely correction is strongly suggested by the surrounding context.
       - Only mark as [unclear] if the meaning is completely lost (use sparingly).
       - Do NOT ‘improve’ already clear wording; only repair corrupted segments.

    3) Style & Tone:
       - Produce natural, fluent {target_language} with the flow of a spoken lecture.
       - Avoid robotic word-for-word translation, but do minimal rewriting: rephrase only when needed for clarity/grammar.

    4) Terminology & Names:
       - Use standard technical equivalents for the specific domain of the lecture.
       - Keep terminology consistent throughout the text.
       - Handle proper names carefully (fix phonetic mishearings if the real person/term is obvious from context).
       - If the real name/term is not clearly identifiable, keep the transcript form (do not guess).

    5) Structure:
       - Fix punctuation and split into logical paragraphs.
       - Do not reorder content.

    Output: Provide ONLY the translated text.

    Text:
    {text}
